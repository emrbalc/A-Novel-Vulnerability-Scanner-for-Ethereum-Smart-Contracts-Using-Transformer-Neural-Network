# CELL 1: Import necessary libraries

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D
import matplotlib.pyplot as plt

# CELL 2: CONFIG
config = {
    "num_words": 150,
    "max_length": 130,
    "embedding_dim": 128,
    "batch_size": 128,
    "epochs": 50,
    "dropout": 0.1,
}

# CELL 3: Read data
df = pd.read_excel('Opcode (1).xlsx')

# CELL 4: Create the Tokenizer and fit on texts
tokenizer = Tokenizer(num_words=config["num_words"], lower=False)
tokenizer.fit_on_texts(df["OPCODE"].values)

# CELL 5: Convert text to sequences
sequences = tokenizer.texts_to_sequences(df["OPCODE"].values)

# CELL 6: Pad sequences
X = pad_sequences(sequences, maxlen=config["max_length"])

# CELL 7: Prepare labels
labels = df['Result'].apply(lambda x: 0 if x == '1 0 0 0' else 1)
y = to_categorical(labels)

# CELL 8: Split data into train, validation, and test
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

# CELL 9: Define the LSTM model
lstm_model = Sequential()
lstm_model.add(Embedding(input_dim=config["num_words"], output_dim=config["embedding_dim"], input_length=config["max_length"]))
lstm_model.add(SpatialDropout1D(config["dropout"]))
lstm_model.add(LSTM(64))
lstm_model.add(Dense(2, activation="softmax"))

# Compile the model
lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])

# CELL 10: Train the LSTM model
lstm_history = lstm_model.fit(X_train, y_train, epochs=config["epochs"], batch_size=config["batch_size"], validation_data=(X_val, y_val))

# Get the history for training and validation metrics
train_loss = lstm_history.history['loss']
train_acc = lstm_history.history['acc']
val_loss = lstm_history.history['val_loss']
val_acc = lstm_history.history['val_acc']

# Evaluate the model on the test set
test_loss, test_acc = lstm_model.evaluate(X_test, y_test)

# Print the results
print("LSTM Model Train Loss:", train_loss[-1])
print("LSTM Model Train Accuracy:", train_acc[-1])
print("LSTM Model Validation Loss:", val_loss[-1])
print("LSTM Model Validation Accuracy:", val_acc[-1])
print("LSTM Model Test Loss:", test_loss)
print("LSTM Model Test Accuracy:", test_acc)

# Draw
plt.figure(figsize=(12, 4))

# Draw training & validation accuracy values
plt.subplot(1, 2, 1)
plt.plot(train_acc, label='Train')
plt.plot(val_acc, label='Validation')
plt.title('LSTM Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.savefig('lstm_train_val_plot.png')
plt.show()

import numpy as np

# test_data
test_data = pd.read_excel('Opcode (1).xlsx', usecols=['Address', 'OPCODE', 'Result'])


# Tokenize the OPCODE
sequences = tokenizer.texts_to_sequences(test_data["OPCODE"].values)
X_test = pad_sequences(sequences, maxlen=config["max_length"])

# Convert the categories to binary labels
y_test = test_data['Result'].apply(lambda x: 0 if x == '1 0 0 0' else 1)

# Convert to categorical
y_test = to_categorical(y_test)

# Evaluate the model
test_loss, test_acc = lstm_model.evaluate(X_test, y_test)

print('LSTM Model Test Loss: {}'.format(test_loss))
print('LSTM Model Test Accuracy: {}'.format(test_acc))

# Get predictions
y_pred = lstm_model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Convert y_test back from one-hot encoding
y_test_classes = np.argmax(y_test, axis=1)

# Generate confusion matrix and classification report
from sklearn.metrics import confusion_matrix, classification_report
cm = confusion_matrix(y_test_classes, y_pred_classes)

print("LSTM Model Confusion Matrix:")
print(cm)

print("LSTM Model Classification Report:")
print(classification_report(y_test_classes, y_pred_classes, target_names=['non vulnerable', 'vulnerable']))

# LSTM modal and train

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

test_data = pd.read_excel('Opcode (1).xlsx', usecols=['Address', 'OPCODE', 'Result'])

test_data = test_data.sample(frac=0.2, random_state=42)

n = test_data[test_data.Result == '1 0 0 0']
s = test_data[test_data.Result == '0 1 0 0']
p = test_data[test_data.Result == '0 0 1 0']
g = test_data[test_data.Result == '0 0 0 1']

catarr = [n, s, p, g]
cat_names = ['non vulnerable', 'suicidial', 'prodigal', 'greedy']

for i, test_cat in enumerate(catarr):
    try:
        print("\nTesting for:", cat_names[i])

        # Process OPCODE data
        tokenizer = Tokenizer(num_words=config["num_words"], lower=False)
        tokenizer.fit_on_texts(test_cat["OPCODE"].values)
        sequences = tokenizer.texts_to_sequences(test_cat["OPCODE"].values)
        x_test_class = np.array(pad_sequences(sequences, maxlen=config["max_length"]))

        # For non vulnerable class, labels are all zeros. For other classes, labels are all ones.
        y_test_class = np.zeros(len(test_cat)) if i == 0 else np.ones(len(test_cat))

        # Evaluate the model
        y_pred = lstm_model.predict(x_test_class)
        y_pred_class = np.round(y_pred[:, 1]).astype(int)

        # Generate confusion matrix
        cm = confusion_matrix(y_test_class, y_pred_class)

        print(f"Test Accuracy: {accuracy_score(y_test_class, y_pred_class)}")
        print("Confusion Matrix: ")
        print(cm)
        print("Classification Report: ")
        print(classification_report(y_test_class, y_pred_class))

    except Exception as e:
        print(f"An error occurred while processing the {cat_names[i]} class. Error: {str(e)}")

# CELL 14: Test the model for each class separately

vulnerability_classes = ['non vulnerable', 'suicidial', 'prodigal', 'greedy']
class_indices = {0: 'non vulnerable', 1: 'suicidial', 2: 'prodigal', 3: 'greedy'}

# Convert y_test back from one-hot encoding
y_test_classes = np.argmax(y_test, axis=1)

for i, vulnerability in enumerate(vulnerability_classes):
    # Get the indices for each class
    indices = np.where(y_test_classes == i)

    # Separate the test data for this class
    x_test_class = X_test[indices]
    y_test_class = y_test[indices]

    # Check if the class has any entries in the test set
    if x_test_class.shape[0] > 0:
        # Evaluate the model on this class
        test_loss, test_acc = lstm_model.evaluate(x_test_class, y_test_class, verbose=0)

        # Get predictions
        y_pred = lstm_model.predict(x_test_class)
        y_pred_classes = np.argmax(y_pred, axis=1)

        # Generate confusion matrix
        from sklearn.metrics import confusion_matrix, classification_report
        cm = confusion_matrix(np.argmax(y_test_class, axis=1), y_pred_classes)

        print(f"\nFor {vulnerability} class:")
        print(f"Test Loss: {test_loss}")
        print(f"Test Accuracy: {test_acc}")
        print("Confusion Matrix: ")
        print(cm)
        print("Classification Report: ")
        print(classification_report(np.argmax(y_test_class, axis=1), y_pred_classes))
    else:
        print(f"No entries in the test set for {vulnerability} class.")
